Directory Contents

This directory contains the following files and subdirectories:

- filtered_rows_N12.csv: A CSV file containing data for properties with 2 or more transactions.
- pp-50k.csv: a subset of the complete data with mainly/all having only 1 transaction per property
- Pipeline_Output: A subdirectory containing output files generated by the pipeline.
- pipeline.py: A Python script that defines the data processing pipeline.

Pipeline Description

The pipeline is designed to process the price paid data and generate output files in the Pipeline_Output subdirectory. The pipeline consists of several stages, including data reading, parsing, grouping, and object creation.

Currently the pipeline.py is set to read the filtered_rows_N12.csv, but can be altered to read any csv within the directroy. Pointed out in the pipeline

Output Files

The pipeline generates output files in the Pipeline_Output subdirectory, which contain the processed data in New Line Delimeted JSON format.


KEY DECISIONS:

- One Major decision was to drop Locality entirely. This is because of its inconsistency and also uselessness.
It appears to be dropped from the actual source data briefly between 1999 and 2000 and then again completely from 2009 onwards.

It is also a field describing the property, so should appear in the property object - not the transaction object. However, due to its incosistent appearance amongst even identical addresses, it would actually lead to duplicated addresses.

Testing was done to assure that the same or a similar thing doe not occur with the other fields within the property object.


- The headers do not exist in the downloaded CSV file and, thus, we have to apply the headers, in the correct order, ourselves. From inspection the schema has never changed, so this is an acceptable method.


- For the Property ID, a combination of Postcode, PAON and SAON is robust enough. This combination is tested and is unique for a given property. It would also allow us to see any potential addresses that have updated/changed/missing Street/District/Town_City/County fields, via duplicated Property IDs. I beleive this will be important, however, as it stands after some testing, I cant see any cases of this.


- The records in the json have been sorted by date of transaction - this is not entirely necessary and can be removed, but does help visualising the json.


- The implemented shard size of 512 MB in Apache Beam should optimise performance by balancing efficient resource management and data transfer, allowing for improved processing speed while minimizing overhead from file handling. This size reduces latency, enhances throughput through parallel processing, and helps maintain manageable file counts, making it a practical choice for many data processing scenarios.



Individual Functions:

1. parse_csv_line(line)
Purpose:
Parses a line from the CSV file into a list of values.

Why It's Required:
This function is essential for converting raw CSV data into a structured format (list) that can be easily processed. It handles any errors during parsing and logs them for debugging.


2. GroupTransactionsByProperty(beam.DoFn)
Purpose:
Groups transactions by a unique key consisting of the property's postcode, PAON (Primary Addressable Object Name), and SAON (Secondary Addressable Object Name).

Why It's Required:
This class defines a custom DoFn that transforms individual transactions into key-value pairs, facilitating the aggregation of transactions related to the same property. This is crucial for later processing, where we need to compile multiple transactions into a single property object.

    - process(self, transaction)
    Purpose:
    Processes a single transaction and extracts the key (postcode, PAON, SAON) along with the transaction data.

    Why It's Required:
    It provides the logic to create a unique identifier for each property based on its address components, allowing for correct grouping in the pipeline.

3. CreatePropertyObject(beam.DoFn)
Purpose:
Transforms grouped transactions into a JSON object representing a property, including details such as postcode, street, and a list of transactions.

Why It's Required:
This class is crucial for structuring the output data. By converting the grouped transactions into a property object, it ensures the final data format meets the desired JSON structure.

    - process(self, key_value)
    Purpose:
    Processes a key-value pair from the grouping step and generates a JSON representation of the property.

    Why It's Required:
    It consolidates information from multiple transactions and extracts relevant details, ensuring the output is comprehensive and structured correctly. Additionally, it generates a unique property ID based on the address components.
